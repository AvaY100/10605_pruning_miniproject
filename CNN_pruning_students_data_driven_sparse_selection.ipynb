{"cells":[{"cell_type":"markdown","metadata":{"id":"y-eC-sb34T9w"},"source":["## Accelerate Inference: Neural Network Pruning"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"L47XBZWm4T9x"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-04-16 01:32:35.578424: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-04-16 01:32:36.427796: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"name":"stdout","output_type":"stream","text":["2.13.1\n"]}],"source":["import os\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","import pickle\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import datasets, layers, models, regularizers\n","from tensorflow.keras.layers import *\n","\n","print(tf.version.VERSION)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"V1FQTVeAuNiU"},"outputs":[{"name":"stdout","output_type":"stream","text":["CNN_pruning_students_.ipynb\t  basic2.h5\t    train_labels.pkl\n","CNN_pruning_students_glenn.ipynb  dataset.tar.gz    val_images.pkl\n","basic.h5\t\t\t  train_images.pkl  val_labels.pkl\n","train_images.pkl\n","train_labels.pkl\n","val_images.pkl\n","val_labels.pkl\n"]}],"source":["# untar\n","!ls\n","!tar -xvzf dataset.tar.gz\n","# load train\n","train_images = pickle.load(open('train_images.pkl', 'rb'))\n","train_labels = pickle.load(open('train_labels.pkl', 'rb'))\n","# load val\n","val_images = pickle.load(open('val_images.pkl', 'rb'))\n","val_labels = pickle.load(open('val_labels.pkl', 'rb'))"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"KE9JuZDG4T94"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-04-16 01:32:40.944697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22295 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:e1:00.0, compute capability: 8.6\n"]}],"source":["# Define the neural network architecture (don't change this)\n","# os.environ['CUDA_VISIBLE_DEVICES'] = '7'\n","model = models.Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5), input_shape=(25,25,3)))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5)))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(5))\n","model.add(Activation('softmax'))"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 25, 25, 32)        896       \n","                                                                 \n"," activation (Activation)     (None, 25, 25, 32)        0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 23, 23, 32)        9248      \n","                                                                 \n"," activation_1 (Activation)   (None, 23, 23, 32)        0         \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 11, 11, 32)        0         \n"," D)                                                              \n","                                                                 \n"," dropout (Dropout)           (None, 11, 11, 32)        0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 11, 11, 64)        18496     \n","                                                                 \n"," activation_2 (Activation)   (None, 11, 11, 64)        0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 9, 9, 64)          36928     \n","                                                                 \n"," activation_3 (Activation)   (None, 9, 9, 64)          0         \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 4, 4, 64)          0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_1 (Dropout)         (None, 4, 4, 64)          0         \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," activation_4 (Activation)   (None, 512)               0         \n","                                                                 \n"," dropout_2 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 5)                 2565      \n","                                                                 \n"," activation_5 (Activation)   (None, 5)                 0         \n","                                                                 \n","=================================================================\n","Total params: 592933 (2.26 MB)\n","Trainable params: 592933 (2.26 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n"]}],"source":["print(model.summary())"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"]},{"name":"stderr","output_type":"stream","text":["2024-04-16 01:32:51.947789: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","2024-04-16 01:32:52.144262: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8900\n","2024-04-16 01:32:53.261075: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n","2024-04-16 01:32:53.273497: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9f855f28b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2024-04-16 01:32:53.273539: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n","2024-04-16 01:32:53.281135: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2024-04-16 01:32:53.416890: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["703/703 [==============================] - 8s 6ms/step - loss: 1.5088 - accuracy: 0.3160 - val_loss: 1.3464 - val_accuracy: 0.4246\n","Epoch 2/50\n","703/703 [==============================] - 4s 5ms/step - loss: 1.3447 - accuracy: 0.4205 - val_loss: 1.2630 - val_accuracy: 0.4594\n","Epoch 3/50\n","703/703 [==============================] - 3s 5ms/step - loss: 1.2848 - accuracy: 0.4576 - val_loss: 1.2259 - val_accuracy: 0.4911\n","Epoch 4/50\n","703/703 [==============================] - 3s 5ms/step - loss: 1.2352 - accuracy: 0.4855 - val_loss: 1.1712 - val_accuracy: 0.5081\n","Epoch 5/50\n","703/703 [==============================] - 4s 5ms/step - loss: 1.2041 - accuracy: 0.5022 - val_loss: 1.1381 - val_accuracy: 0.5366\n","Epoch 6/50\n","703/703 [==============================] - 4s 5ms/step - loss: 1.1695 - accuracy: 0.5223 - val_loss: 1.1121 - val_accuracy: 0.5406\n","Epoch 7/50\n","703/703 [==============================] - 4s 5ms/step - loss: 1.1413 - accuracy: 0.5370 - val_loss: 1.1003 - val_accuracy: 0.5501\n","Epoch 8/50\n","703/703 [==============================] - 4s 6ms/step - loss: 1.1150 - accuracy: 0.5494 - val_loss: 1.0943 - val_accuracy: 0.5414\n","Epoch 9/50\n","703/703 [==============================] - 4s 6ms/step - loss: 1.0916 - accuracy: 0.5624 - val_loss: 1.0394 - val_accuracy: 0.5798\n","Epoch 10/50\n","703/703 [==============================] - 4s 6ms/step - loss: 1.0684 - accuracy: 0.5733 - val_loss: 1.0182 - val_accuracy: 0.5893\n","Epoch 11/50\n","703/703 [==============================] - 4s 5ms/step - loss: 1.0484 - accuracy: 0.5816 - val_loss: 1.0053 - val_accuracy: 0.5913\n","Epoch 12/50\n","703/703 [==============================] - 4s 6ms/step - loss: 1.0335 - accuracy: 0.5887 - val_loss: 0.9944 - val_accuracy: 0.5917\n","Epoch 13/50\n","703/703 [==============================] - 4s 6ms/step - loss: 1.0204 - accuracy: 0.5962 - val_loss: 0.9741 - val_accuracy: 0.6075\n","Epoch 14/50\n","703/703 [==============================] - 4s 6ms/step - loss: 1.0026 - accuracy: 0.6046 - val_loss: 0.9595 - val_accuracy: 0.6107\n","Epoch 15/50\n","703/703 [==============================] - 4s 6ms/step - loss: 0.9847 - accuracy: 0.6099 - val_loss: 0.9735 - val_accuracy: 0.6044\n","Epoch 16/50\n","703/703 [==============================] - 4s 6ms/step - loss: 0.9695 - accuracy: 0.6178 - val_loss: 0.9568 - val_accuracy: 0.6111\n","Epoch 17/50\n","703/703 [==============================] - 4s 6ms/step - loss: 0.9594 - accuracy: 0.6207 - val_loss: 0.9470 - val_accuracy: 0.6182\n","Epoch 18/50\n","703/703 [==============================] - 4s 6ms/step - loss: 0.9406 - accuracy: 0.6335 - val_loss: 0.9432 - val_accuracy: 0.6194\n","Epoch 19/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.9322 - accuracy: 0.6347 - val_loss: 0.8994 - val_accuracy: 0.6349\n","Epoch 20/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.9167 - accuracy: 0.6434 - val_loss: 0.8927 - val_accuracy: 0.6412\n","Epoch 21/50\n","703/703 [==============================] - 3s 5ms/step - loss: 0.9075 - accuracy: 0.6489 - val_loss: 0.8938 - val_accuracy: 0.6440\n","Epoch 22/50\n","703/703 [==============================] - 3s 5ms/step - loss: 0.8898 - accuracy: 0.6549 - val_loss: 0.8786 - val_accuracy: 0.6483\n","Epoch 23/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.8790 - accuracy: 0.6623 - val_loss: 0.8761 - val_accuracy: 0.6455\n","Epoch 24/50\n","703/703 [==============================] - 3s 5ms/step - loss: 0.8706 - accuracy: 0.6621 - val_loss: 0.8650 - val_accuracy: 0.6455\n","Epoch 25/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.8587 - accuracy: 0.6684 - val_loss: 0.8607 - val_accuracy: 0.6499\n","Epoch 26/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.8513 - accuracy: 0.6739 - val_loss: 0.9004 - val_accuracy: 0.6384\n","Epoch 27/50\n","703/703 [==============================] - 3s 5ms/step - loss: 0.8356 - accuracy: 0.6788 - val_loss: 0.8283 - val_accuracy: 0.6657\n","Epoch 28/50\n","703/703 [==============================] - 4s 6ms/step - loss: 0.8246 - accuracy: 0.6849 - val_loss: 0.8475 - val_accuracy: 0.6602\n","Epoch 29/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.8134 - accuracy: 0.6886 - val_loss: 0.8487 - val_accuracy: 0.6562\n","Epoch 30/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.8099 - accuracy: 0.6876 - val_loss: 0.8313 - val_accuracy: 0.6725\n","Epoch 31/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.7952 - accuracy: 0.6960 - val_loss: 0.8302 - val_accuracy: 0.6618\n","Epoch 32/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.7903 - accuracy: 0.6985 - val_loss: 0.8434 - val_accuracy: 0.6626\n","Epoch 33/50\n","703/703 [==============================] - 4s 6ms/step - loss: 0.7804 - accuracy: 0.7046 - val_loss: 0.8043 - val_accuracy: 0.6848\n","Epoch 34/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.7696 - accuracy: 0.7065 - val_loss: 0.7999 - val_accuracy: 0.6832\n","Epoch 35/50\n","703/703 [==============================] - 4s 6ms/step - loss: 0.7575 - accuracy: 0.7092 - val_loss: 0.8052 - val_accuracy: 0.6737\n","Epoch 36/50\n","703/703 [==============================] - 4s 6ms/step - loss: 0.7493 - accuracy: 0.7139 - val_loss: 0.7898 - val_accuracy: 0.6832\n","Epoch 37/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.7388 - accuracy: 0.7172 - val_loss: 0.7973 - val_accuracy: 0.6796\n","Epoch 38/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.7305 - accuracy: 0.7236 - val_loss: 0.7815 - val_accuracy: 0.6855\n","Epoch 39/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.7268 - accuracy: 0.7242 - val_loss: 0.7740 - val_accuracy: 0.6887\n","Epoch 40/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.7181 - accuracy: 0.7270 - val_loss: 0.7714 - val_accuracy: 0.6998\n","Epoch 41/50\n","703/703 [==============================] - 3s 5ms/step - loss: 0.7067 - accuracy: 0.7337 - val_loss: 0.7620 - val_accuracy: 0.6982\n","Epoch 42/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.7011 - accuracy: 0.7362 - val_loss: 0.7673 - val_accuracy: 0.7034\n","Epoch 43/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.6913 - accuracy: 0.7364 - val_loss: 0.7522 - val_accuracy: 0.7026\n","Epoch 44/50\n","703/703 [==============================] - 3s 5ms/step - loss: 0.6918 - accuracy: 0.7405 - val_loss: 0.7645 - val_accuracy: 0.6954\n","Epoch 45/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.6786 - accuracy: 0.7460 - val_loss: 0.7735 - val_accuracy: 0.6939\n","Epoch 46/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.6731 - accuracy: 0.7457 - val_loss: 0.7459 - val_accuracy: 0.7014\n","Epoch 47/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.6686 - accuracy: 0.7463 - val_loss: 0.7515 - val_accuracy: 0.7097\n","Epoch 48/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.6517 - accuracy: 0.7549 - val_loss: 0.7764 - val_accuracy: 0.6935\n","Epoch 49/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.6459 - accuracy: 0.7576 - val_loss: 0.7581 - val_accuracy: 0.6970\n","Epoch 50/50\n","703/703 [==============================] - 4s 5ms/step - loss: 0.6450 - accuracy: 0.7579 - val_loss: 0.7658 - val_accuracy: 0.6962\n"]}],"source":["# you can use the default hyper-parameters for training,\n","# val accuracy ~72% after 50 epochs\n","\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, weight_decay=1e-6),\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n","              metrics=['accuracy'])\n","\n","history = model.fit(train_images, train_labels, batch_size=32, epochs=50,\n","                    validation_data=(val_images, val_labels)) # train for 50 epochs, with batch size 32"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" 1/20 [>.............................] - ETA: 0s - loss: 1.0630 - accuracy: 0.5938"]},{"name":"stdout","output_type":"stream","text":["20/20 [==============================] - 0s 3ms/step - loss: 0.7658 - accuracy: 0.6958\n"]}],"source":["results = model.evaluate(val_images, val_labels, batch_size=128)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # perform pruning here\n","\n","# # get the weights\n","# weights = model.get_weights()\n","\n","# # you can use set_weights() to set some weights to zero, e.g.,\n","\n","# weights[7][:10]=0\n","# model.set_weights(weights)"]},{"cell_type":"markdown","metadata":{},"source":["### Next, we use the method introduced in the paper [Data-Driven Sparse Structure Selection for Deep Neural Networks](https://arxiv.org/pdf/1707.01213.pdf). We adjust the original method to this case."]},{"cell_type":"markdown","metadata":{},"source":["#### First implement sparse scaling layer (supporting weights)."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["from tensorflow.keras.layers import Layer\n","import tensorflow as tf\n","\n","class SparseScaling(Layer):\n","    def __init__(self, **kwargs):\n","        super(SparseScaling, self).__init__(**kwargs)\n","        self.gamma = 0.01\n","\n","    def build(self, input_shape):\n","        self.scale = self.add_weight(name='scale', \n","                                     shape=(input_shape[-1],),\n","                                     initializer='ones',\n","                                     regularizer=tf.keras.regularizers.l1(self.gamma),\n","                                     trainable=True)\n","        super(SparseScaling, self).build(input_shape)\n","\n","    def call(self, inputs):\n","        return inputs * self.scale"]},{"cell_type":"markdown","metadata":{},"source":["#### Next, insert this layer after each existing layer.\n","#####\n"," We found that since the sparse layer already acts as a penalty term added to the original weights, the l2 regularizer can be removed here, and experiments have proven that this will yield better results."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# os.environ['CUDA_VISIBLE_DEVICES'] = '7'\n","\n","model = models.Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same', input_shape=(25,25,3)))\n","model.add(Activation('relu'))\n","model.add(SparseScaling())\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(SparseScaling())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(SparseScaling())\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(SparseScaling())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(SparseScaling())\n","model.add(Dropout(0.5))\n","model.add(Dense(5))\n","model.add(Activation('softmax'))"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0 (3, 3, 3, 32)\n","1 (32,)\n","2 (32,)\n","3 (3, 3, 32, 32)\n","4 (32,)\n","5 (32,)\n","6 (3, 3, 32, 64)\n","7 (64,)\n","8 (64,)\n","9 (3, 3, 64, 64)\n","10 (64,)\n","11 (64,)\n","12 (1024, 512)\n","13 (512,)\n","14 (512,)\n","15 (512, 5)\n","16 (5,)\n"]}],"source":["# take a look at the structure\n","weights = model.get_weights()\n","for i in range(len(weights)):\n","    print(i, weights[i].shape)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_5 (Conv2D)           (None, 25, 25, 32)        896       \n","                                                                 \n"," activation_7 (Activation)   (None, 25, 25, 32)        0         \n","                                                                 \n"," sparse_scaling (SparseScal  (None, 25, 25, 32)        32        \n"," ing)                                                            \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 23, 23, 32)        9248      \n","                                                                 \n"," activation_8 (Activation)   (None, 23, 23, 32)        0         \n","                                                                 \n"," sparse_scaling_1 (SparseSc  (None, 23, 23, 32)        32        \n"," aling)                                                          \n","                                                                 \n"," max_pooling2d_2 (MaxPoolin  (None, 11, 11, 32)        0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_3 (Dropout)         (None, 11, 11, 32)        0         \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 11, 11, 64)        18496     \n","                                                                 \n"," activation_9 (Activation)   (None, 11, 11, 64)        0         \n","                                                                 \n"," sparse_scaling_2 (SparseSc  (None, 11, 11, 64)        64        \n"," aling)                                                          \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 9, 9, 64)          36928     \n","                                                                 \n"," activation_10 (Activation)  (None, 9, 9, 64)          0         \n","                                                                 \n"," sparse_scaling_3 (SparseSc  (None, 9, 9, 64)          64        \n"," aling)                                                          \n","                                                                 \n"," max_pooling2d_3 (MaxPoolin  (None, 4, 4, 64)          0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_4 (Dropout)         (None, 4, 4, 64)          0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 1024)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 512)               524800    \n","                                                                 \n"," activation_11 (Activation)  (None, 512)               0         \n","                                                                 \n"," sparse_scaling_4 (SparseSc  (None, 512)               512       \n"," aling)                                                          \n","                                                                 \n"," dropout_5 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 5)                 2565      \n","                                                                 \n"," activation_12 (Activation)  (None, 5)                 0         \n","                                                                 \n","=================================================================\n","Total params: 593637 (2.26 MB)\n","Trainable params: 593637 (2.26 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n"]}],"source":["print(model.summary())"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"]},{"name":"stderr","output_type":"stream","text":["2024-04-16 01:39:22.300390: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_2/dropout_3/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"]},{"name":"stdout","output_type":"stream","text":["703/703 [==============================] - 7s 6ms/step - loss: 6.1113 - accuracy: 0.3566 - val_loss: 3.6930 - val_accuracy: 0.4333\n","Epoch 2/50\n","703/703 [==============================] - 4s 6ms/step - loss: 2.2570 - accuracy: 0.4047 - val_loss: 1.7222 - val_accuracy: 0.3925\n","Epoch 3/50\n","703/703 [==============================] - 4s 6ms/step - loss: 1.6825 - accuracy: 0.4026 - val_loss: 1.5998 - val_accuracy: 0.4250\n","Epoch 4/50\n","703/703 [==============================] - 4s 6ms/step - loss: 1.6006 - accuracy: 0.4160 - val_loss: 1.5276 - val_accuracy: 0.4242\n","Epoch 5/50\n","703/703 [==============================] - 4s 6ms/step - loss: 1.5523 - accuracy: 0.4288 - val_loss: 1.5025 - val_accuracy: 0.4218\n","Epoch 6/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.5134 - accuracy: 0.4386 - val_loss: 1.4657 - val_accuracy: 0.4550\n","Epoch 7/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.4954 - accuracy: 0.4367 - val_loss: 1.4847 - val_accuracy: 0.4115\n","Epoch 8/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.4723 - accuracy: 0.4460 - val_loss: 1.4429 - val_accuracy: 0.4436\n","Epoch 9/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.4542 - accuracy: 0.4472 - val_loss: 1.4226 - val_accuracy: 0.4614\n","Epoch 10/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.4363 - accuracy: 0.4543 - val_loss: 1.4024 - val_accuracy: 0.4630\n","Epoch 11/50\n","703/703 [==============================] - 5s 6ms/step - loss: 1.4225 - accuracy: 0.4582 - val_loss: 1.3902 - val_accuracy: 0.4677\n","Epoch 12/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.4142 - accuracy: 0.4622 - val_loss: 1.3897 - val_accuracy: 0.4511\n","Epoch 13/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.4026 - accuracy: 0.4625 - val_loss: 1.4054 - val_accuracy: 0.4463\n","Epoch 14/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.3940 - accuracy: 0.4665 - val_loss: 1.3536 - val_accuracy: 0.4836\n","Epoch 15/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.3839 - accuracy: 0.4686 - val_loss: 1.3525 - val_accuracy: 0.4764\n","Epoch 16/50\n","703/703 [==============================] - 4s 6ms/step - loss: 1.3774 - accuracy: 0.4731 - val_loss: 1.3387 - val_accuracy: 0.4756\n","Epoch 17/50\n","703/703 [==============================] - 4s 6ms/step - loss: 1.3718 - accuracy: 0.4730 - val_loss: 1.3360 - val_accuracy: 0.4808\n","Epoch 18/50\n","703/703 [==============================] - 4s 6ms/step - loss: 1.3662 - accuracy: 0.4783 - val_loss: 1.3294 - val_accuracy: 0.4792\n","Epoch 19/50\n","703/703 [==============================] - 4s 6ms/step - loss: 1.3563 - accuracy: 0.4785 - val_loss: 1.3222 - val_accuracy: 0.4887\n","Epoch 20/50\n","703/703 [==============================] - 4s 6ms/step - loss: 1.3493 - accuracy: 0.4783 - val_loss: 1.3230 - val_accuracy: 0.4768\n","Epoch 21/50\n","703/703 [==============================] - 4s 6ms/step - loss: 1.3472 - accuracy: 0.4830 - val_loss: 1.3144 - val_accuracy: 0.4867\n","Epoch 22/50\n","703/703 [==============================] - 4s 6ms/step - loss: 1.3448 - accuracy: 0.4835 - val_loss: 1.3209 - val_accuracy: 0.4796\n","Epoch 23/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.3398 - accuracy: 0.4832 - val_loss: 1.3097 - val_accuracy: 0.4788\n","Epoch 24/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.3365 - accuracy: 0.4859 - val_loss: 1.3029 - val_accuracy: 0.4891\n","Epoch 25/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.3299 - accuracy: 0.4885 - val_loss: 1.3210 - val_accuracy: 0.4772\n","Epoch 26/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.3260 - accuracy: 0.4905 - val_loss: 1.2861 - val_accuracy: 0.5038\n","Epoch 27/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.3221 - accuracy: 0.4950 - val_loss: 1.2837 - val_accuracy: 0.4978\n","Epoch 28/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.3153 - accuracy: 0.4947 - val_loss: 1.2697 - val_accuracy: 0.4978\n","Epoch 29/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.3096 - accuracy: 0.4977 - val_loss: 1.3162 - val_accuracy: 0.4665\n","Epoch 30/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.3083 - accuracy: 0.5013 - val_loss: 1.2711 - val_accuracy: 0.5105\n","Epoch 31/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.3062 - accuracy: 0.5006 - val_loss: 1.2715 - val_accuracy: 0.5081\n","Epoch 32/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.3015 - accuracy: 0.5017 - val_loss: 1.2687 - val_accuracy: 0.5050\n","Epoch 33/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.3004 - accuracy: 0.5023 - val_loss: 1.2534 - val_accuracy: 0.5133\n","Epoch 34/50\n","703/703 [==============================] - 5s 6ms/step - loss: 1.2929 - accuracy: 0.5049 - val_loss: 1.2577 - val_accuracy: 0.5216\n","Epoch 35/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.2888 - accuracy: 0.5078 - val_loss: 1.2482 - val_accuracy: 0.5117\n","Epoch 36/50\n","703/703 [==============================] - 4s 6ms/step - loss: 1.2839 - accuracy: 0.5125 - val_loss: 1.2625 - val_accuracy: 0.5081\n","Epoch 37/50\n","703/703 [==============================] - 4s 6ms/step - loss: 1.2846 - accuracy: 0.5105 - val_loss: 1.2354 - val_accuracy: 0.5244\n","Epoch 38/50\n","703/703 [==============================] - 4s 6ms/step - loss: 1.2806 - accuracy: 0.5088 - val_loss: 1.2375 - val_accuracy: 0.5295\n","Epoch 39/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.2772 - accuracy: 0.5141 - val_loss: 1.2335 - val_accuracy: 0.5220\n","Epoch 40/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.2804 - accuracy: 0.5164 - val_loss: 1.2365 - val_accuracy: 0.5283\n","Epoch 41/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.2749 - accuracy: 0.5165 - val_loss: 1.2702 - val_accuracy: 0.5069\n","Epoch 42/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.2675 - accuracy: 0.5176 - val_loss: 1.2269 - val_accuracy: 0.5263\n","Epoch 43/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.2675 - accuracy: 0.5177 - val_loss: 1.2494 - val_accuracy: 0.5145\n","Epoch 44/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.2622 - accuracy: 0.5230 - val_loss: 1.2090 - val_accuracy: 0.5418\n","Epoch 45/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.2610 - accuracy: 0.5239 - val_loss: 1.2222 - val_accuracy: 0.5378\n","Epoch 46/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.2594 - accuracy: 0.5258 - val_loss: 1.2280 - val_accuracy: 0.5303\n","Epoch 47/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.2545 - accuracy: 0.5236 - val_loss: 1.2107 - val_accuracy: 0.5446\n","Epoch 48/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.2542 - accuracy: 0.5311 - val_loss: 1.2215 - val_accuracy: 0.5394\n","Epoch 49/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.2478 - accuracy: 0.5309 - val_loss: 1.1859 - val_accuracy: 0.5529\n","Epoch 50/50\n","703/703 [==============================] - 5s 7ms/step - loss: 1.2434 - accuracy: 0.5333 - val_loss: 1.2178 - val_accuracy: 0.5350\n"]}],"source":["model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001, weight_decay=1e-6),\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n","              metrics=['accuracy'])\n","\n","history = model.fit(train_images, train_labels, batch_size=32, epochs=50,\n","                    validation_data=(val_images, val_labels)) # train for 50 epochs, with batch size 32"]},{"cell_type":"code","execution_count":671,"metadata":{"id":"vOhpP7M24T9_"},"outputs":[{"name":"stdout","output_type":"stream","text":["20/20 [==============================] - 0s 3ms/step - loss: 0.8912 - accuracy: 0.7232\n"]}],"source":["results = model.evaluate(val_images, val_labels, batch_size=128)"]},{"cell_type":"markdown","metadata":{},"source":["### Next mask out the structure (kernels, neurons, ...) whose corresponding scaling factor is below a threshold."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def prune_weights(model):\n","    for i, layer in enumerate(model.layers):\n","        if isinstance(layer, SparseScaling):\n","            scale_factors = np.abs(layer.scale.numpy())\n","            if i == 2: # first conv layer\n","                previous_layer = model.layers[i-2]\n","                weights, biases = previous_layer.get_weights()\n","                new_weights = weights * (scale_factors >= 0.1)\n","                previous_layer.set_weights([new_weights, biases])\n","            if i == 5: # second conv layer\n","                previous_layer = model.layers[i-2]\n","                weights, biases = previous_layer.get_weights()\n","                new_weights = weights * (scale_factors >= 0.1)\n","                previous_layer.set_weights([new_weights, biases])\n","            if i == 10: # third conv layer\n","                previous_layer = model.layers[i-2]\n","                weights, biases = previous_layer.get_weights()\n","                new_weights = weights * (scale_factors >= 0.155)\n","                previous_layer.set_weights([new_weights, biases])\n","            if i == 13: # forth conv layer\n","                previous_layer = model.layers[i-2]\n","                weights, biases = previous_layer.get_weights()\n","                new_weights = weights * (scale_factors >= 0.06)\n","                previous_layer.set_weights([new_weights, biases])\n","            if i == 19: # first dense layer\n","                previous_layer = model.layers[i-2]\n","                weights, biases = previous_layer.get_weights()\n","                new_weights = weights * (scale_factors >= 0.035)\n","                previous_layer.set_weights([new_weights, biases])\n","\n","prune_weights(model)"]},{"cell_type":"markdown","metadata":{},"source":["### Remove the supporting weights (scaling factors)."]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["def transfer_weights(original_model, new_model):\n","    original_layers = [layer for layer in original_model.layers if not isinstance(layer, SparseScaling)]\n","    new_layers = new_model.layers\n","    assert len(original_layers) == len(new_layers), \"Layer count must match between the models.\"\n","    for orig_layer, new_layer in zip(original_layers, new_layers):\n","        if isinstance(orig_layer, type(new_layer)):\n","            new_layer.set_weights(orig_layer.get_weights())\n","\n","\n","new_model = models.Sequential([\n","    Conv2D(32, (3, 3), padding='same', input_shape=(25,25,3)),\n","    Activation('relu'),\n","    Conv2D(32, (3, 3)),\n","    Activation('relu'),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Dropout(0.25),\n","    Conv2D(64, (3, 3), padding='same'),\n","    Activation('relu'),\n","    Conv2D(64, (3, 3)),\n","    Activation('relu'),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Dropout(0.25),\n","    Flatten(),\n","    Dense(512),\n","    Activation('relu'),\n","    Dropout(0.5),\n","    Dense(5),\n","    Activation('softmax')\n","])\n","\n","transfer_weights(model, new_model)"]},{"cell_type":"markdown","metadata":{},"source":["#### Retrain the model with deprecated structures masked out."]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["from tensorflow.keras.callbacks import Callback\n","\n","class PruneWeights(Callback):\n","    def __init__(self, masks):\n","        super(PruneWeights, self).__init__()\n","        self.masks = masks\n","\n","    # def on_epoch_end(self, epoch, logs=None):\n","    #     for i, layer in enumerate(self.model.layers):\n","    #         if isinstance(layer, (tf.keras.layers.Conv2D, tf.keras.layers.Dense)):\n","    #             weights, biases = layer.get_weights()\n","    #             weights *= self.masks[i]\n","    #             layer.set_weights([weights, biases])\n","\n","    def on_train_batch_end(self, batch, logs=None):\n","        for i, layer in enumerate(self.model.layers):\n","            if isinstance(layer, (tf.keras.layers.Conv2D, tf.keras.layers.Dense)):\n","                weights, biases = layer.get_weights()\n","                weights *= self.masks[i]\n","                layer.set_weights([weights, biases])\n","    \n","\n","def generate_pruning_mask(model):\n","    mask = []\n","    for layer in model.layers:\n","        if isinstance(layer, (tf.keras.layers.Conv2D, tf.keras.layers.Dense)):\n","            weights, biases = layer.get_weights()\n","            layer_mask = (weights != 0).astype(float)\n","            mask.append(layer_mask)\n","        else:\n","            mask.append(None)\n","    return mask"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["pruning_mask = generate_pruning_mask(new_model)\n","prune_callback = PruneWeights(masks=pruning_mask)\n","# print(pruning_mask[0])"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# save model while training\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","checkpoint_filepath = 'my_model_weights_best.h5'\n","model_checkpoint_callback = ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=False,\n","    monitor='val_loss',\n","    mode='min',\n","    save_best_only=True,\n","    verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, weight_decay=1e-6),\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n","              metrics=['accuracy'])\n","new_model.fit(train_images, train_labels, batch_size=32, epochs=500, validation_data=(val_images, val_labels), callbacks=[prune_callback, model_checkpoint_callback])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_model.load_weights('my_model_weights_best.h5')\n","\n","results = new_model.evaluate(val_images, val_labels, batch_size=128)\n","\n","def calculate_zero_weights_ratio(model):\n","    total_weights = 0\n","    zero_weights = 0\n","    for layer in model.layers:\n","        if hasattr(layer, 'get_weights') and len(layer.get_weights()) > 0:\n","            weights = layer.get_weights()[0]\n","            total_weights += np.size(weights)\n","            zero_weights += np.count_nonzero(weights == 0)\n","    if total_weights == 0:\n","        return 0\n","    else:\n","        return zero_weights / total_weights\n","\n","calculate_zero_weights_ratio(new_model)"]},{"cell_type":"markdown","metadata":{},"source":["### We also combine this method with L1 norm."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = models.Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same', input_shape=(25,25,3), kernel_regularizer=regularizers.l1(0.01)))\n","model.add(Activation('relu'))\n","model.add(SparseScaling())\n","model.add(Conv2D(32, (3, 3), kernel_regularizer=regularizers.l1(0.01)))\n","model.add(Activation('relu'))\n","model.add(SparseScaling())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l1(0.01)))\n","model.add(Activation('relu'))\n","model.add(SparseScaling())\n","model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l1(0.01)))\n","model.add(Activation('relu'))\n","model.add(SparseScaling())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(512), kernel_regularizer=regularizers.l1(0.01))\n","model.add(Activation('relu'))\n","model.add(SparseScaling())\n","model.add(Dropout(0.5))\n","model.add(Dense(5), kernel_regularizer=regularizers.l1(0.01))\n","model.add(Activation('softmax'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.load_weights('my_model_weights_best.h5')\n","\n","pruning_mask = generate_pruning_mask(model)\n","prune_callback = PruneWeights(masks=pruning_mask)\n","\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, weight_decay=1e-6),\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n","              metrics=['accuracy'])\n","model.fit(train_images, train_labels, batch_size=32, epochs=200, validation_data=(val_images, val_labels), callbacks=[prune_callback])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["weights = model.get_weights()\n","for i in range(len(weights)):\n","    layer_weights = model.get_weights()[i]\n","    modified_weights = np.where(np.abs(layer_weights) < 0.1, 0, layer_weights)\n","    weights[i] = modified_weights\n","    model.set_weights(weights)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":77,"metadata":{"id":"wMSKQW4k4T-G"},"outputs":[],"source":["# you need to save the model's weights, naming it 'my_model_weights.h5'\n","new_model.save_weights(\"my_model_weights.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# running this cell will immediately download a file called 'my_model_weights.h5'\n","from google.colab import files\n","files.download(\"my_model_weights.h5\")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1w20Vhx_MxwY8mVmLORuQcAMSpCdIKmGb","timestamp":1662737366034},{"file_id":"1-kM27DCVOvQ0iPbvNqvHyMNpEBkagy9Q","timestamp":1603749902126},{"file_id":"1TVz0yWqJXl98n1Jnrs-IkBe2fnniRg_9","timestamp":1603747597083}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":0}
